---
title: "AI Internship Evaluation"
author: "Xiaoxuan (Jessie) Yang"
date: "1/3/2019"
output: pdf_document
---

```{r Setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
set.seed(2019)

# Install and load packages
# install.packages("here")
# install.packages("tidyverse")
# install.packages("dplyr")
# install.packages("lubricate")
# install.packages("tm")
# install.packages("tidytext") 
# install.packages("ggplot2")
# install.packages("Hmisc")
# install.packages("eply")
# install.packages("cleanNLP")
# install.packages("knitr")
# install.packages("kableExtra")
# install.packages("topicmodels")

library(here) # create subdirectory and file path
library(dplyr)
library(lubridate) # to tidy up date
library(tidyverse)
library(tibble)
library(readr)
library(tm) # used to create corpora
library(tidytext) # used for tokenization
library(ggplot2)
library(Hmisc) # used to capitalize genre names
library(eply) # get rid of the quotation marks of genres
library(cleanNLP) 
library(knitr)
library(kableExtra) # display tables in r markdown

# Set color-blind friendly palette
  cbPalette <- c("#999999", 
                 "#E69F00", 
                 "#56B4E9", 
                 "#009E73", 
                 "#F0E442", 
                 "#0072B2", 
                 "#D55E00", 
                 "#CC79A7")

# To use for fills, add
  scale_fill_manual(values=cbPalette)
  
# To use for line and point colors, add
  scale_colour_manual(values=cbPalette)

```


```{r Load raw Wikipedia movie summaries }

movie_data <- as_tibble(read_csv("movie_data.csv",
                                   col_types = cols(
                                     id = col_integer(),
                                     title = col_character(),
                                     release_date = col_character(), 
                                     box_office_revenue = col_number(),
                                     runtime = col_double(),
                                     genres = col_character(),
                                     summary = col_character()
                                    )
                                )
                        ) # using tibble to avoid converting strings to factors

# Check parsing failures
  problems(movie_data) # parsing failure in the date column

  dim(movie_data) # check dimension: 42204x7
  

```


```{r Data cleaning for year and genre columns}
# Clean the date column
  # Create a Year column
  movie_data[,"year"]<-year(as.Date(movie_data$release_date, "%Y",
                                    tryFormats = c("yyyy", "yyyy-mm-dd", "yyyy-mm")))
  
  # Remove a movie made in 1010
  movie_data <- movie_data[!grepl("Hunting Season", movie_data$title),]

# Clean the genre column  
  # Eliminate space and convert two-word category into one-word
  movie_data$genres <- gsub(" ", "", movie_data$genres ) # e.g. "romance film" -> "romancefilm"
  
  # Eliminate the bracket, backslash, and comma (leave a space) in the genre column
  movie_data$genres <- gsub("\\[|\\]", "", movie_data$genres)
  movie_data$genres <- gsub("\\", "", movie_data$genres, fixed= TRUE)    
  movie_data$genres <- gsub(",", " ", movie_data$genres)
    
     
  # Unify similar movie genre
  movie_data$genres <- gsub("Coming-of-agefilm", "Comingofage", movie_data$genres)
  movie_data$genres <- gsub("Filmu00e0clef", "", movie_data$genres)
  movie_data$genres <- gsub("Dogme95", "", movie_data$genres)
  movie_data$genres <- gsub("Educational", "Education", movie_data$genres)
  movie_data$genres <- gsub("Children's/Family", "Children's", movie_data$genres)
  movie_data$genres <- gsub("Biographicalfilm", "Biography", movie_data$genres)
  # not going to include more due to time limit
  
    
# Eliminate missing values for the genres
  # check missing value for each column
  colSums(sapply(movie_data, is.na)) # genres has "[]" as the form of missing value
  
  # filter out empty cells in the genres column
  movie_data <- filter(movie_data, genres != "") 
  
    
# Remove duplicates
  # check duplicate rows
  sum(duplicated(movie_data)) # 0 

  # check duplicate summary--assumption: no films should share the same summary
  dedup.movie_data <- movie_data[!duplicated(movie_data$summary),] 
  
  

# Lower case (only for genres)
  dedup.movie_data$genres <- tolower(dedup.movie_data$genres)  
  
# Check dimensions
  dim(dedup.movie_data) # check dimension: 41784 x 8

# Save the cleaned dataset
  saveRDS(dedup.movie_data, here::here("rds_data", "data_clean.rds"))

```


```{r Plot numbers of released movies vs. year}
# Load the cleaned dataset
  movie_data <- readRDS(here::here("rds_data", "data_clean.rds"))

# Eliminate NAs in year
  movie_data <- filter(movie_data, year != "") 

  ggplot(movie_data, aes(year)) +
    geom_bar() +
    labs(x = "Released Year", y = "Movie Count", title = "Histogram of Movie Released") +
    theme(plot.title = element_text(hjust = 0.5))
```


```{r tm: Calculate genre frequency by creating corpus}
# Load the cleaned dataset
  movie_data <- readRDS(here::here("rds_data", "data_clean.rds"))


##### Create Corpus for Movie Genres #####
  genre <- Corpus(VectorSource(movie_data$genres))
  genre_dtm <- DocumentTermMatrix(genre)  # create a document-term matrix from a Corpus object
  genre_freq <- colSums(as.matrix(genre_dtm))
  freq <- sort(colSums(as.matrix(genre_dtm)), decreasing=TRUE) 
  genre_wf <- data.frame(Word=names(freq), Frequency=freq)
  genre_wf$Word <- unquote(genre_wf$Word) # eliminate the quotation marks
  rownames(genre_wf) <- NULL  # eliminate rownames
  
  # Manually add space to movie genres
  genre_wf$Word[genre_wf$Word == "romancefilm"] <- "Romance Film"
  genre_wf$Word[genre_wf$Word == "worldcinema"] <- "World Cinema"
  genre_wf$Word[genre_wf$Word == "crimefiction"] <- "Crime Fiction"
  
  genre_wf$Word <- capitalize(genre_wf$Word)
  
  # Save the cleaned genre frequency
  saveRDS(genre_wf, here::here("rds_data", "genre_frequency.rds"))
  
```


```{r Find the most produced movie genres}
##### Plot out the top produced genres #####
  # Load the cleaned dataset
  genre_wf <- readRDS(here::here("rds_data", "genre_frequency.rds"))
  
  genre_wf %>%
      rename(
        Word = word, 
        Frequency = freq
      ) %>%
      arrange(desc(Frequency)) %>%
      top_n(10, Frequency ) %>%
      ggplot(aes(x = reorder(Word, Frequency), Frequency)) +
      geom_bar(position="dodge",stat="identity", fill = "#E69F00", width = 0.6) +
      labs(x = NULL, y = "Genre Frequency ($)") +
      theme(text = element_text(size=14), 
            axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))) +
      ggtitle("Top 10 Most Produced Movie Genres") +
      coord_flip()
```


```{r Calculate the sum of box office revenue by year and genre}
# Load the cleaned dataset
  movie_data <- readRDS(here::here("rds_data", "data_clean.rds"))

# Remove rows with NAs in the box office revenue column
  revenue_movie<- movie_data %>%
    filter(box_office_revenue > 0)

  list_revenue <- genre_wf$word
  
##### Compile revenues based on genre #####
    # Create an empty tibble to compile all genres
      revenue <- as.tibble(matrix(ncol=2, nrow=0)) 

    for (i in 1:length(list_revenue)){
      
      selected_genre = tolower(as.character(list_revenue[i]))
    
    # Filter the revenue based on the genre
      revenue_dataset <- revenue_movie %>% 
        filter(str_detect(genres, selected_genre)) %>% 
        mutate(genre = selected_genre) %>%
        select(box_office_revenue, genre, year)
      
      print(paste("Running line", i))
      revenue <- rbind(revenue, revenue_dataset) # compile
    }
      

# Calculate mean based on genre and year
    sum_revenue <- revenue %>%
        group_by(genre, year) %>%
        filter(genre != "film") %>%
        summarise(sum= sum(box_office_revenue, na.rm = TRUE))
  
    sum_revenue$genre <- unquote(sum_revenue$genre) # eliminate the quotation marks
    
     # Manually add space to movie genres
    sum_revenue$genre[sum_revenue$genre == "romancefilm"] <- "Romance Film"
    sum_revenue$genre[sum_revenue$genre == "worldcinema"] <- "World Cinema"
    sum_revenue$genre[sum_revenue$genre == "crimefiction"] <- "Crime Fiction"
    sum_revenue$genre[sum_revenue$genre == "familyfilm"] <- "Family Film"
    sum_revenue$genre[sum_revenue$genre == "sciencefiction"] <- "Science Fiction"
    
    sum_revenue$genre <- capitalize(sum_revenue$genre)
  
    # Save the cleaned dataset
    saveRDS(sum_revenue, here::here("rds_data", "movie_revenue.rds"))
```


```{r Find the top profitable movie genres}    
    # Load the cleaned dataset
    sum_revenue <- readRDS(here::here("rds_data", "movie_revenue.rds"))
    
    sum_revenue %>%
      group_by(genre) %>%
      summarise("Sum_Revenue" = sum(sum)) %>%
      arrange(desc(Sum_Revenue)) %>%
      top_n(10, Sum_Revenue ) %>%
      ggplot(aes(x = reorder(genre, Sum_Revenue), Sum_Revenue)) +
      geom_bar(position="dodge",stat="identity", fill = "#E69F00", width = 0.6) +
      labs(x = NULL, y = "Total Box Office Revenue ($)") +
      theme(text = element_text(size=14), 
            axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))) +
      ggtitle("Top 10 Profitable Movie Genres") +
      coord_flip()
```


```{r Subset dataset with top five most produced movie genres}
# Load the cleaned dataset
  movie_data <- readRDS(here::here("rds_data", "data_clean.rds"))

# We select the top five movie genres
  list_genre <- c("drama", "comedy", "romancefilm", "thriller", "action")  

# Create an empty tibble to compile five genres
  topfive <- as.tibble(matrix(ncol=2, nrow=0)) 

  
##### Compile data for the top five most produced movie genres #####
for (i in 1:5){
  selected_genre = list_genre[i]
  
  # Filter the summary based on the genre
    topfive_dataset <- movie_data %>% 
      filter(str_detect(genres, selected_genre)) %>% 
      select(summary) %>%
      mutate(summary, 
             genre = selected_genre)
    
    topfive <- rbind(topfive, topfive_dataset) # compile dataset
  }
  
  
# We will use this selected genres dataset to conduct the rest of the analysis  
  topfive_dataset <- topfive
  
  # edit the genre names
  topfive_dataset$genre[topfive_dataset$genre == "romancefilm"] <- "Romance Film"
  topfive_dataset$genre<-capitalize(topfive_dataset$genre)
  
  
# Save the top five genre dataset
  saveRDS(topfive_dataset, here::here("rds_data", "data_topfive.rds"))
  
```


```{r cleanNLP: Run annotator}

# install.packages("reticulate")
  library(reticulate)
  use_python(python = '/usr/local/bin/python3') 

# Check python configuration
  py_config()

# Load the cleanNLP
  library(cleanNLP)

# Initialize the NLP backend
  cnlp_init_spacy(model_name = "en")

# Load summaries of top five movie genres dataset
  topfive_dataset <- readRDS(here::here("rds_data", "data_topfive.rds"))

# Run the annotator for each genre from text folder
  object <- cnlp_annotate(topfive_dataset$summary, doc_ids = topfive_dataset$genre) 
  saveRDS(object, here::here("rds_data", "anno_topfive_bygenre.rds"))
  
```


```{r cleanNLP: Analyze annotation}
# Load the annotation dataset
  anno <- readRDS(here::here("rds_data", "anno_topfive_bygenre.rds"))
# Extract tokens 
  token <- cnlp_get_token(anno)
##### See most frequently used nouns #####

# Pull out the token table
  token_table <- token %>%
    filter(upos == "NOUN") %>%
    filter(!lemma == "film") %>%
  group_by(id, lemma) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  ungroup() 
  
# Plot most frequent words used in movie summaries in top five genres  
  token_table %>%
    arrange(desc(count)) %>%
    group_by(id) %>%
    top_n(5) %>%
    ungroup %>%
    ggplot(aes(x = reorder(lemma, -count), y = count, fill = id)) +
      geom_bar(position="dodge",stat="identity", width = 0.5, show.legend = FALSE) +
      labs(x = NULL, y = "Counts") +
      facet_wrap(~id, ncol = 2, scales = "free") +
      coord_flip()
  
# Plot for each genre
    list_genre <- c("Drama", "Comedy", "Romance Film", "Thriller", "Action")  

    for (i in 1:5){
        selected_genre = list_genre[i]
        color = cbPalette[i]
      # Filter the summary based on the genre
        plot <- token_table %>% 
          filter(id == selected_genre) %>% 
          arrange(desc(count)) %>%
          top_n(5) %>%
          ggplot(aes(x = reorder(lemma, count), y = count)) +
            geom_bar(position="dodge",stat="identity", 
                     fill = color, width = 0.5, show.legend = FALSE) +
            labs(x = NULL, y = "Counts", title = selected_genre) +
            coord_flip()
    }
  
    plot_grid(ncol = 3, nrow = 2)

  

##### See most mentioned places in each summary #####
  entity <- cnlp_get_entity(anno)

  entity.df <- entity %>%
    filter(entity_type == "GPE") %>%
    count(id, entity, sort = TRUE) 


  entity.df %>%
    arrange(desc(n)) %>%
    mutate(entity = factor(entity, levels = rev(unique(entity)))) %>%
    group_by(id) %>%
    top_n(5) %>%
    ungroup %>%
    ggplot(aes(entity, n, fill = id)) +
      geom_col(show.legend = FALSE) +
      xlab("Number of Observation") + ylab("Places Mentioned") +
      theme(text = element_text(size=14), axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0)))  +
      facet_wrap(~id, ncol = 2, scales = "free_y") +
      coord_flip()

  
  
```


```{r CleanNLP: Topic modeling}
# Load the annotation dataset
  anno <- readRDS(here::here("rds_data", "anno_topfive_bygenre.rds"))

# Load Topic Models
  library(topicmodels)

# Pull out the dependency table with built-in option to auto join with token table
  dep <- cnlp_get_token(anno) %>%
    filter(pos %in% c("NN", "NNS")) %>%
    cnlp_utils_tfidf(min_df = 0.05, max_df = 0.95, 
                     type = "tf", tf_weight = "raw") 
  
# Create a five-topic model
  tm_movies <- LDA(dep, k = 5, control = list(seed = 1234))
  
  saveRDS(tm_movies, here::here("rds_data", "five-topic LDA.rds"))
```

```{r Examine document and topic relationship}  
  tm_movies <- readRDS(here::here("rds_data", "five-topic LDA.rds"))
  
##### Examine per-term-per-topic probabilities #####
  chapters_topics <- tidy(tm_movies, matrix = "beta")
  
# Modify topic column  
  chapters_topics$topic[chapters_topics$topic == 1] <- "Topic 1"
  chapters_topics$topic[chapters_topics$topic == 2] <- "Topic 2"
  chapters_topics$topic[chapters_topics$topic == 3] <- "Topic 3"
  chapters_topics$topic[chapters_topics$topic == 4] <- "Topic 4"
  chapters_topics$topic[chapters_topics$topic == 5] <- "Topic 5"

  saveRDS(chapters_topics, here::here("rds_data", "beta_LDA_table.rds"))
  
  plot_topwords <-  chapters_topics %>%
    group_by(topic) %>%
    top_n(5, beta) %>%
    ungroup() %>%
    arrange(topic, -beta) %>%
    mutate(term = reorder(term, beta)) %>%
    ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    labs(x = "Per-topic-per-word Probabilities", y = "Terms") +
    theme_minimal(base_size = 10) +
    theme(plot.caption = element_text(hjust = 4)) +
    scale_fill_manual(values=cbPalette) +
    facet_wrap(~topic, scales = "free") +
    coord_flip()

    saveRDS(plot_topwords, here::here("image", "Beta_LDA.rds"))

##### Examine per-document-per-topic #####
  chapters_gamma <- tidy(tm_movies, matrix = "gamma")

  # convert to a table format
  table_gamma <- spread(chapters_gamma, topic, gamma)
  colnames(table_gamma) <- c("Genre", "Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5")
  rownames(table_gamma) <- table_gamma$Genre
  
  saveRDS(table_gamma, here::here("rds_data", "gamma_LDA_table.rds"))
  
  # prevent scientific expression
  options("scipen"=999, "digits"=2)

  # plot the table for document frequency
  table_gamma[, 2:6] %>%
    mutate(
      Genre = row.names(table_gamma)) %>%
    select(Genre, everything()) %>%
    kable("html", escape = F) %>%
    kable_styling(bootstrap_options = "basic", full_width = F) %>%
    column_spec(5, width = "3cm") 


```


```{r Check Zipfs law}

# Load top five produced genres
  topfive_words <- readRDS(here::here("rds_data", "words_topfive.rds"))

##### Plot out term frequency distribution for each genre #####
    ggplot(topfive_words, aes(n/total, fill = genre)) +
      geom_histogram(show.legend = FALSE) +
      xlim(NA, 0.00003) +
      xlab("Term Frequency") + ylab("Counts of Words") +
      facet_wrap(~genre, ncol = 2, scales = "free_y")  # Many words occur rarely and fewer words (e.g. stop words) occur frequently
    

  # Examine Zipf's law for five genres
    freq_by_rank <- topfive_words %>%
      group_by(genre) %>%
      mutate(rank = row_number(),
             "term_frequency" = n/total)
    
##### Plot rank vs. frequency in log-log coordinates #####
    freq_by_rank %>% 
      ggplot(aes(rank, term_frequency, color = genre)) + 
      geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) +
      xlab("Rank") + ylab("Term Frequency") +
      labs(colour= "Top Five Popular Movie Genres") +
      scale_x_continuous(trans='log10') +
      scale_y_continuous(trans='log10')

# topfive_words <- readRDS(here::here("rds_data", "words_topfive.rds"))  

# Examine Zipf's law for five genres
    freq_by_rank <- topfive_words %>%
      group_by(genre) %>%
      mutate(rank = row_number(),
             "term_frequency" = n/total)

  # Select the middle portion to find the exponent of the power law
    rank_subset <- freq_by_rank %>% 
      filter(rank < 5000,
      rank > 80)
      
    lm <- lm(log10(term_frequency) ~ log10(rank), data = rank_subset)
      
##### Fit a curve that follows Zipf's law #####
    freq_by_rank %>% 
      ggplot(aes(rank, term_frequency, color = genre)) + 
      coord_fixed() +
      geom_abline(intercept = lm$coefficients[1], slope = lm$coefficients[2], color = "gray50", linetype = 2) +
      geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) + 
      xlab("Rank") + ylab("Term Frequency") +
      labs(colour= "Top Five Popular Movie Genres") +
      scale_x_continuous(trans='log10') +
      scale_y_continuous(trans='log10') +
      theme(legend.title = element_text(colour="Black", size=10, 
                                      face="bold"))+
      scale_colour_manual(values=cbPalette)
    
    
    
```


### More attempt

```{r Tidytext: Analyze term frequency by removing stopwords}
topfive_dataset <- readRDS(here::here("rds_data", "data_topfive.rds"))

# Customize stopwords
  my_stop_words <- bind_rows(stop_words, 
                           data_frame(word = c("film"), 
                                      lexicon = rep("custom", 30)))

##### Tokenization and stopwords removal #####
  topfive_words_nostop <- topfive_dataset %>%
    unnest_tokens(word, summary) %>%
    filter(!word %in% my_stop_words$word,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word, "[a-z]")) %>%
    count(genre, word, sort = TRUE) %>%
    ungroup()

##### Calculate word frequencies for top five genres #####
  total_words_nostop <- topfive_words_nostop %>%
    group_by(genre) %>%
    summarise(total=sum(n))
  
  # Include total words for each row
  topfive_words_nostop <- left_join(topfive_words_nostop, total_words_nostop)
  
  frequency_nostop <- topfive_words_nostop %>%
    mutate(freq = n/total)
  
##### Plot term frequencies for five genres #####
  common_words <- frequency_nostop %>%
    group_by(genre) %>%
    top_n(10, freq) %>%
    ungroup() %>%
    arrange(genre, -freq)

  common_words %>%
  mutate(word = reorder(word, freq)) %>%
  group_by(genre, word) %>%    
  arrange(desc(freq)) %>%  
  ungroup() %>%
  mutate(word = factor(paste(word, genre, sep = "__"), 
                       levels = rev(paste(word, genre, sep = "__")))) %>%
  ggplot(aes(word, freq, fill = as.factor(genre))) +
    geom_col(show.legend = FALSE) +
    coord_flip() +
    scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
    labs(title = "Top 10 terms in each genre",
         x = NULL, y = expression(freq)) +
    facet_wrap(~ genre, ncol = 3, scales = "free")
 
 
  
  

```     


```{r Tidytext: Analyze term frequency+inverse document frequency}

# Load genre dataset
  topfive_dataset <- readRDS(here("rds_data", "data_topfive.rds"))

##### One word per token in tokenization (without eliminating stop words) #####
  topfive_words <- topfive_dataset %>%
    unnest_tokens(word, summary) %>%
    filter(str_detect(word, "[a-z]")) %>%
    count(genre, word, sort = TRUE) %>%
    ungroup()

  # Total words in those genres
  total_words <- topfive_words %>%
    group_by(genre) %>%
    summarise(total=sum(n))
  
  # Include total words for each row
  topfive_words <- left_join(topfive_words, total_words)
  
  saveRDS(topfive_words, here::here("rds_data", "words_topfive.rds"))   
  
# Combine inverse document frequency with term frequency 
  topfive_words <- topfive_words %>%
    bind_tf_idf(word, genre, n)
  
# Look at terms with high tf-idf
  topfive_words %>%
    select(-total) %>%
    arrange(desc(tf_idf))

# Visualization high tf-idf words
  topfive_words %>%
    arrange(desc(tf_idf)) %>%
    mutate(word = factor(word, levels = rev(unique(word)))) %>% 
    group_by(genre) %>% 
    top_n(10) %>% 
    ungroup %>%
    ggplot(aes(word, tf_idf, fill = genre)) +
    geom_col(show.legend = FALSE) +
    labs(x = NULL, y = "tf-idf") +
    facet_wrap(~genre, ncol = 3, scales = "free") +
    coord_flip()

##### Two words as consecutive sequences (n=2) in tokenization #####
  topfive_bigrams <- topfive_dataset %>%
      unnest_tokens(bigram, summary, token = "ngrams", n=2) 
      
  topfive_bigrams %>%
    count(bigram, sort = TRUE)
  
  bigrams_separated <- topfive_bigrams %>%
    separate(bigram, c("word1", "word2"), sep = " ")
  
  bigrams_filtered <- bigrams_separated %>%
    filter(!word1 %in% stop_words$word) %>%
    filter(!word2 %in% stop_words$word)
  
  # new bigram counts:
  bigram_counts <- bigrams_filtered %>% 
    count(word1, word2, sort = TRUE)
  
  bigrams_united <- bigrams_filtered %>%
    unite(bigram, word1, word2, sep = " ")
  
  bigram_tf_idf <- bigrams_united %>%
    count(genre, bigram) %>%
    bind_tf_idf(bigram, genre, n) %>%
    arrange(desc(tf_idf))

```


```{r Check session info}
sessionInfo()
```

