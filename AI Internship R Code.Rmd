---
title: "AI Internship Evaluation"
author: "Xiaoxuan (Jessie) Yang"
date: "1/3/2019"
output: pdf_document
---
# Set up
```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)

# Install and load packages
# install.packages("tidyverse")
# install.packages("dplyr")
# install.packages("lubridate")
# install.packages("tm")
# install.packages("tidytext") 
# install.packages("ggplot2")
# install.packages("SnowballC")
# install.packages("Hmisc")

library("dplyr")
library("tidyverse")
library("tibble")
library("readr")
library("lubridate")
library("tm") # used to create corpora
library("tidytext") # used for tokenization
library("ggplot2")
library("SnowballC")
library("Hmisc") # used to capitalize genre names

# Set color-blind friendly palette
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# To use for fills, add
  scale_fill_manual(values=cbPalette)
  
# To use for line and point colors, add
  scale_colour_manual(values=cbPalette)

```


# Load the raw data
```{r}

movie_data <- as_tibble(read_csv("~/Coding_AI/movie_data.csv",
                                   col_types = cols(
                                     id = col_integer(),
                                     title = col_character(),
                                     release_date = col_character(), # using col_date causes parsing failures
                                     box_office_revenue = col_number(),
                                     runtime = col_double(),
                                     genres = col_character(),
                                     summary = col_character()
                                    )
                                )
                        ) # using tibble to avoid converting strings to factors

# Check parsing failures
problems(movie_data) # parsing failure in the date column

dim(movie_data) # check dimension: 42204x7


```


# Data preprocessing
```{r}
# Clean date 
  # Create a Year column
  movie_data[,"year"]<-year(as.Date(movie_data$release_date, "%Y",tryFormats = c("yyyy", "yyyy-mm-dd", "yyyy-mm")))


# Eliminate missing values for the genres
  # check missing value for each column
  colSums(sapply(movie_data, is.na)) # genres has "[]" as the form of missing value
  
  # filter out empty cells in the genres column
  movie_data <- filter(movie_data, genres != "[]") 
  
# Clean the genre column  
  # Eliminate the bracket in the genre column
    movie_data$genres <- gsub("\\[|\\]", "", movie_data$genres)
    
  # Eliminate space and convert two-word category into one-word
    movie_data$genres <- gsub(" ", "", movie_data$genres ) # e.g. "romance film" -> "romancefilm"
  
  # Elimiate the comma
    movie_data$genres <- gsub(",", " ", movie_data$genres)

# Remove duplicates
  # check duplicate rows
  sum(duplicated(movie_data)) # 0 

  # check duplicate summary--assumption: no films should share the same summary
  dedup.movie_data <- movie_data[!duplicated(movie_data$summary),] 
  
# Lower case (only for genres)
    dedup.movie_data$genres <- tolower(dedup.movie_data$genres)  
  
dim(dedup.movie_data) # check dimension: 42196 x 8

movie_data <- dedup.movie_data
```

# Find most produced genres by creating corpus objects
```{r}
# Create Corpus   
  genre <- Corpus(VectorSource(movie_data$genres))
  genre_dtm <- DocumentTermMatrix(genre)  # create a document-term matrix from a Corpus object
  
  genre_freq <- colSums(as.matrix(genre_dtm))
  freq <- sort(colSums(as.matrix(genre_dtm)), decreasing=TRUE) 
  genre_wf <- data.frame(word=names(genre_freq), freq=freq)
  rownames(genre_wf) <- NULL  # eliminate rownames

  
```

# most profitable genres 
```{r}
# Remove rows with NAs in the box office revenue column
  revenue_movie<- movie_data %>%
    filter(box_office_revenue > 0)

# Create updated corpus for all genres after filtering   
  genre_r <- Corpus(VectorSource( revenue_movie$genres))
  genre_dtm_r <- DocumentTermMatrix(genre_r)
  
  genre_freq_r <- colSums(as.matrix(genre_dtm_r))
  freq_r <- sort(colSums(as.matrix(genre_dtm_r)), decreasing=TRUE) 
  genre_wf_r <- data.frame(word=names(genre_freq_r), freq=genre_freq)
    
# Plot out the top profitable genres
  
```

# Select the top five movie genres and create a dataset for finding summary characteristics 
```{r}
# We select the top five movie genres
  list_genre <- c("drama", "comedy", "romancefilm", "thriller", "action")  

# Create an empty tibble to compile five genres
  topfive <- as.tibble(matrix(ncol=2, nrow=0)) 

# Use a loop to compile
for (i in 1:5){
  selected_genre = list_genre[i]
  
  # Filter the summary based on the genre
    topfive_dataset <- movie_data %>% 
      filter(str_detect(genres, selected_genre)) %>% 
      select(summary) %>%
      mutate(summary, 
             genre = selected_genre)
    
    topfive <- rbind(topfive, topfive_dataset) # compile
  }
  
# We will use this selected genres dataset to conduct the rest of the analysis  
  topfive_dataset <- topfive
  
  # edit the genre names
  topfive_dataset$genre[topfive_dataset$genre == "romancefilm"] <- "Romance Film"
  topfive_dataset$genre<-capitalize(topfive_dataset$genre)
  
  
```


# Common words used in the summaries
```{r}

# Tokenization
  topfive_words <- topfive_dataset %>%
    unnest_tokens(word, summary) %>%
    count(genre, word, sort = TRUE) %>%
    ungroup()

  # Total words in those genres
  total_words <- topfive_words %>%
    group_by(genre) %>%
    summarise(total=sum(n))
  
  # Include total words for each row
  topfive_words <- left_join(topfive_words, total_words)

  
# Remove stop words
  tidy_char_movie <- tidy_char_movie %>%
    anti_join(stop_words) 
    ungroup()
    
    
# Counts and word frequency
  char_movie %>%
    count(word, sort = TRUE) %>%
    filter(n>2000) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip()
  
```

# Plot dendrogram to identify word groups used in each genre

```{r}

```


# Check if the summary follows Zipf's law
```{r}

##### top five popular genres #####

  # Plot out Term Frequency Distributionfor each genre  
    ggplot(topfive_words, aes(n/total, fill = genre)) +
      geom_histogram(show.legend = FALSE) +
      xlim(NA, 0.00005) +
      facet_wrap(~genre, ncol = 2, scales = "free_y")  # Many words occur rarely and fewer words (e.g. stop words) occur frequently

  # Examine Zipf's law for five genres
    freq_by_rank <- topfive_words %>%
      group_by(genre) %>%
      mutate(rank = row_number(),
             "term_frequency" = n/total)
    
  # Plot rank vs. frequency in log-log coordinates
    freq_by_rank %>% 
      ggplot(aes(rank, term_frequency, color = genre)) + 
      geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) +
      xlab("Rank") + ylab("Term Frequency") +
      labs(colour= "Top Five Popular Movie Genres") +
      scale_x_continuous(trans='log10') +
      scale_y_continuous(trans='log10')

  # Select the middle portion to find the exponent of the power law
    rank_subset <- freq_by_rank %>% 
      filter(rank < 5000,
      rank > 80)
      
    lm(log10(term_frequency) ~ log10(rank), data = rank_subset)
      
  # Fit a curve that follows Zipf's law
    freq_by_rank %>% 
      ggplot(aes(rank, term_frequency, color = genre)) + 
      geom_abline(intercept = -0.9354, slope = -1.02, color = "gray50", linetype = 2) +
      geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
      xlab("Rank") + ylab("Term Frequency") +
      labs(colour= "Top Five Popular Movie Genres") +
      scale_x_continuous(trans='log10') +
      scale_y_continuous(trans='log10')
        
    
```



```{r}
sessionInfo()
```

