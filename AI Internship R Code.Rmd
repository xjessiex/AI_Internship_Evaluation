---
title: "AI Internship Evaluation"
author: "Xiaoxuan (Jessie) Yang"
date: "1/3/2019"
output: pdf_document
---

```{r Setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)


# Install and load packages
# install.packages("here")
# install.packages("tidyverse")
# install.packages("dplyr")
# install.packages("lubridate")
# install.packages("tm")
# install.packages("tidytext") 
# install.packages("ggplot2")
# install.packages("Hmisc")
# install.packages("formattable")
# install.packages("eply")


library("here")
library("dplyr")
library("tidyverse")
library("tibble")
library("readr")
library("lubridate")
library("tm") # used to create corpora
library("tidytext") # used for tokenization
library("ggplot2")
library("Hmisc") # used to capitalize genre names
library("formattable") # used to plot most profitable genres
library("eply") # get rid of the quotation marks of genres

# Set color-blind friendly palette
  cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# To use for fills, add
  scale_fill_manual(values=cbPalette)
  
# To use for line and point colors, add
  scale_colour_manual(values=cbPalette)

```


```{r Load raw Wikipedia movie summaries }

movie_data <- as_tibble(read_csv("movie_data.csv",
                                   col_types = cols(
                                     id = col_integer(),
                                     title = col_character(),
                                     release_date = col_character(), # using col_date causes parsing failures
                                     box_office_revenue = col_number(),
                                     runtime = col_double(),
                                     genres = col_character(),
                                     summary = col_character()
                                    )
                                )
                        ) # using tibble to avoid converting strings to factors

# Check parsing failures
problems(movie_data) # parsing failure in the date column

dim(movie_data) # check dimension: 42204x7


```



```{r Data cleaning for year and genre columns}
# Clean the date column
  # Create a Year column
  movie_data[,"year"]<-year(as.Date(movie_data$release_date, "%Y",tryFormats = c("yyyy", "yyyy-mm-dd", "yyyy-mm")))
  
  # Remove a movie made in 1010
  movie_data <- movie_data[!grepl("Hunting Season", movie_data$title),]

# Clean the genre column  
  # Eliminate space and convert two-word category into one-word
    movie_data$genres <- gsub(" ", "", movie_data$genres ) # e.g. "romance film" -> "romancefilm"
  
    # Eliminate the bracket, backslash, and comma (leave a space) in the genre column
    movie_data$genres <- gsub("\\[|\\]", "", movie_data$genres)
    movie_data$genres <- gsub("\\", "", movie_data$genres, fixed= TRUE)
    movie_data$genres <- gsub(",", " ", movie_data$genres)
    
     
  # Unify similar movie genre
    movie_data$genres <- gsub("Coming-of-agefilm", "Comingofage", movie_data$genres)
    movie_data$genres <- gsub("Filmu00e0clef", "", movie_data$genres)
    movie_data$genres <- gsub("Dogme95", "", movie_data$genres)
    movie_data$genres <- gsub("Educational", "Education", movie_data$genres)
    movie_data$genres <- gsub("Children's/Family", "Children's", movie_data$genres)
    movie_data$genres <- gsub("Biographicalfilm", "Biography", movie_data$genres)
    # not going to include more due to time limit
  
    
# Eliminate missing values for the genres
  # check missing value for each column
  colSums(sapply(movie_data, is.na)) # genres has "[]" as the form of missing value
  
  # filter out empty cells in the genres column
  movie_data <- filter(movie_data, genres != "") 
  
    
# Remove duplicates
  # check duplicate rows
  sum(duplicated(movie_data)) # 0 

  # check duplicate summary--assumption: no films should share the same summary
  dedup.movie_data <- movie_data[!duplicated(movie_data$summary),] 
  
# Lower case (only for genres)
    dedup.movie_data$genres <- tolower(dedup.movie_data$genres)  
  
  
dim(dedup.movie_data) # check dimension: 41784 x 8

# Save the cleaned dataset
  saveRDS(dedup.movie_data, "data_clean.rds")

```


```{r Plot numbers of released movies vs. year}
# Load the cleaned dataset
movie_data <- readRDS("data_clean.rds")

  ggplot(movie_data, aes(year)) +
    geom_bar() +
    labs(x = "Released Year", y = "Movie Count", title = "Histogram of Movie Released") +
    theme(plot.title = element_text(hjust = 0.5))
```

```{r Find most produced genres by calculating genre frequency}

##### Create Corpus for Movie Genres #####
  genre <- Corpus(VectorSource(movie_data$genres))
  genre_dtm <- DocumentTermMatrix(genre)  # create a document-term matrix from a Corpus object
  
  genre_freq <- colSums(as.matrix(genre_dtm))
  freq <- sort(colSums(as.matrix(genre_dtm)), decreasing=TRUE) 
  genre_wf <- data.frame(word=names(freq), freq=freq)
  genre_wf$word <- unquote(genre_wf$word) # eliminate the quotation marks
  rownames(genre_wf) <- NULL  # eliminate rownames
  
##### Plot out the top produced genres #####
  
  
```

```{r Find top five profitable genres based on box office revenue}

# Remove rows with NAs in the box office revenue column
  revenue_movie<- movie_data %>%
    filter(box_office_revenue > 0)

  list_revenue <- genre_wf$word
  
##### Compile revenues based on genre #####
    # Create an empty tibble to compile all genres
      revenue <- as.tibble(matrix(ncol=2, nrow=0)) 
    
    for (i in 1:length(list_revenue)){
      
      selected_genre = as.character(list_revenue[i])
    
    # Filter the revenue based on the genre
      revenue_dataset <- revenue_movie %>% 
        filter(str_detect(genres, selected_genre)) %>% 
        mutate(genre = selected_genre) %>%
        select(box_office_revenue, genre, year)
      
      print(i)
      revenue <- rbind(revenue, revenue_dataset) # compile
    }
      

# Calculate mean based on genre and year
    sum_revenue <- revenue %>%
        group_by(genre, year) %>%
        filter(genre != "film") %>%
        summarise(sum= sum(box_office_revenue, na.rm = TRUE))
  
    sum_revenue$genre <- unquote(sum_revenue$genre) # eliminate the quotation marks
    
    sum_revenue %>%
      group_by(genre) %>%
      summarise("Sum_Revenue" = sum(sum)) %>%
      arrange(desc(Sum_Revenue)) %>%
      top_n(5, Sum_Revenue) %>%
      formattable(list(Sum_Revenue = color_bar("orange")), align = 'l')
  
      
# Create updated corpus for filtered genres 
    genre_r <- Corpus(VectorSource(revenue_movie$genres))
    genre_dtm_r <- DocumentTermMatrix(genre_r)
    
    genre_freq_r <- colSums(as.matrix(genre_dtm_r))
    freq_r <- sort(colSums(as.matrix(genre_dtm_r)), decreasing=TRUE) 
    genre_wf_r <- data.frame(word=names(genre_freq_r), freq=freq_r)      
  
```


```{r Subset dataset with top five most produced movie genres}
# We select the top five movie genres
  list_genre <- c("drama", "comedy", "romancefilm", "thriller", "action")  

# Create an empty tibble to compile five genres
  topfive <- as.tibble(matrix(ncol=2, nrow=0)) 

##### Compile top five most produced movie genres #####
for (i in 1:5){
  selected_genre = list_genre[i]
  
  # Filter the summary based on the genre
    topfive_dataset <- movie_data %>% 
      filter(str_detect(genres, selected_genre)) %>% 
      select(summary) %>%
      mutate(summary, 
             genre = selected_genre)
    
    topfive <- rbind(topfive, topfive_dataset) # compile
  }
  
# We will use this selected genres dataset to conduct the rest of the analysis  
  topfive_dataset <- topfive
  
  # edit the genre names
  topfive_dataset$genre[topfive_dataset$genre == "romancefilm"] <- "Romance Film"
  topfive_dataset$genre<-capitalize(topfive_dataset$genre)
  
  
# Save the top five genre dataset
  saveRDS(topfive_dataset, "data_topfive.rds")
  
```


```{r Analyze term frequency by removing stopwords}
topfive_dataset <- readRDS("data_topfive.rds")

# Customize stopwords
  my_stop_words <- bind_rows(stop_words, 
                           data_frame(word = c("film"), 
                                      lexicon = rep("custom", 30)))

##### Tokenization and stopwords removal #####
  topfive_words_nostop <- topfive_dataset %>%
    unnest_tokens(word, summary) %>%
    filter(!word %in% my_stop_words$word,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word, "[a-z]")) %>%
    count(genre, word, sort = TRUE) %>%
    ungroup()

##### Calculate word frequencies for top five genres #####
  total_words_nostop <- topfive_words_nostop %>%
    group_by(genre) %>%
    summarise(total=sum(n))
  
  # Include total words for each row
  topfive_words_nostop <- left_join(topfive_words_nostop, total_words_nostop)
  
  frequency_nostop <- topfive_words_nostop %>%
    mutate(freq = n/total)
  
##### Plot term frequencies for five genres #####
  common_words <- frequency_nostop %>%
    group_by(genre) %>%
    top_n(10, freq) %>%
    ungroup() %>%
    arrange(genre, -freq)

  common_words %>%
  mutate(word = reorder(word, freq)) %>%
  group_by(genre, word) %>%    
  arrange(desc(freq)) %>%  
  ungroup() %>%
  mutate(word = factor(paste(word, genre, sep = "__"), 
                       levels = rev(paste(word, genre, sep = "__")))) %>%
  ggplot(aes(word, freq, fill = as.factor(genre))) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
  labs(title = "Top 10 terms in each genre",
       x = NULL, y = expression(freq)) +
  facet_wrap(~ genre, ncol = 3, scales = "free")
 
 

```     

  
```{r Analyze term frequency+inverse document frequency}

##### One word per token in tokenization (without eliminating stop words) #####
  topfive_words <- topfive_dataset %>%
    unnest_tokens(word, summary) %>%
    filter(str_detect(word, "[a-z]")) %>%
    count(genre, word, sort = TRUE) %>%
    ungroup()

  # Total words in those genres
  total_words <- topfive_words %>%
    group_by(genre) %>%
    summarise(total=sum(n))
  
  # Include total words for each row
  topfive_words <- left_join(topfive_words, total_words)
  
  
 saveRDS(topfive_words, "words_topfive.rds")     
  
# Combine inverse document frequency with term frequency 
  topfive_words <- topfive_words %>%
    bind_tf_idf(word, genre, n)
  
# Look at terms with high tf-idf
  topfive_words %>%
    select(-total) %>%
    arrange(desc(tf_idf))

# Visualization high tf-idf words
  topfive_words %>%
    arrange(desc(tf_idf)) %>%
    mutate(word = factor(word, levels = rev(unique(word)))) %>% 
    group_by(genre) %>% 
    top_n(10) %>% 
    ungroup %>%
    ggplot(aes(word, tf_idf, fill = genre)) +
    geom_col(show.legend = FALSE) +
    labs(x = NULL, y = "tf-idf") +
    facet_wrap(~genre, ncol = 3, scales = "free") +
    coord_flip()

##### Two words as consecutive sequences (n=2) in tokenization #####
  topfive_bigrams <- topfive_dataset %>%
      unnest_tokens(bigram, summary, token = "ngrams", n=2) 
      
  topfive_bigrams %>%
    count(bigram, sort = TRUE)
  
  bigrams_separated <- topfive_bigrams %>%
    separate(bigram, c("word1", "word2"), sep = " ")
  
  bigrams_filtered <- bigrams_separated %>%
    filter(!word1 %in% stop_words$word) %>%
    filter(!word2 %in% stop_words$word)
  
  # new bigram counts:
  bigram_counts <- bigrams_filtered %>% 
    count(word1, word2, sort = TRUE)
  
  bigrams_united <- bigrams_filtered %>%
    unite(bigram, word1, word2, sep = " ")
  
  bigram_tf_idf <- bigrams_united %>%
    count(genre, bigram) %>%
    bind_tf_idf(bigram, genre, n) %>%
    arrange(desc(tf_idf))

```



```{r Check Zipf's law}

# Load top five produced genres
  topfive_words <- readRDS(here("words_topfive.rds"))

##### Plot out term frequency distributionfor each genre #####
    ggplot(topfive_words, aes(n/total, fill = genre)) +
      geom_histogram(show.legend = FALSE) +
      xlim(NA, 0.00003) +
      facet_wrap(~genre, ncol = 2, scales = "free_y")  # Many words occur rarely and fewer words (e.g. stop words) occur frequently
    

  # Examine Zipf's law for five genres
    freq_by_rank <- topfive_words %>%
      group_by(genre) %>%
      mutate(rank = row_number(),
             "term_frequency" = n/total)
    
##### Plot rank vs. frequency in log-log coordinates #####
    freq_by_rank %>% 
      ggplot(aes(rank, term_frequency, color = genre)) + 
      geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) +
      xlab("Rank") + ylab("Term Frequency") +
      labs(colour= "Top Five Popular Movie Genres") +
      scale_x_continuous(trans='log10') +
      scale_y_continuous(trans='log10')

  # Select the middle portion to find the exponent of the power law
    rank_subset <- freq_by_rank %>% 
      filter(rank < 5000,
      rank > 80)
      
    lm(log10(term_frequency) ~ log10(rank), data = rank_subset)
      
##### Fit a curve that follows Zipf's law #####
    freq_by_rank %>% 
      ggplot(aes(rank, term_frequency, color = genre)) + 
      geom_abline(intercept = -0.9354, slope = -1.02, color = "gray50", linetype = 2) +
      geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) + 
      xlab("Rank") + ylab("Term Frequency") +
      labs(colour= "Top Five Popular Movie Genres") +
      scale_x_continuous(trans='log10') +
      scale_y_continuous(trans='log10')
        
    
```



```{r Check session info}
sessionInfo()
```

