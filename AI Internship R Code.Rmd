---
title: "AI Internship Evaluation"
author: "Xiaoxuan (Jessie) Yang"
date: "1/3/2019"
output: pdf_document
---
# Set up
```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)

# Install and load packages
# install.packages("tidyverse")
# install.packages("dplyr")
# install.packages("lubridate")
# install.packages("tm")
# install.packages("tidytext") 
# install.packages("ggplot2")

library("dplyr")
library("tidyverse")
library("tibble")
library("readr")
library("lubridate")
library("tm") # used to create corpora
library("tidytext") # used for tokenization
library("ggplot2")

# Load the raw data
movie_data <- as_tibble(read_csv("~/Coding_AI/movie_data.csv",
                                   col_types = cols(
                                     id = col_integer(),
                                     title = col_character(),
                                     release_date = col_character(), # using col_date causes parsing failures
                                     box_office_revenue = col_number(),
                                     runtime = col_double(),
                                     genres = col_character(),
                                     summary = col_character()
                                    )
                                )
                        ) # using tibble to avoid converting strings to factors


# Check parsing failures
problems(movie_data) # parsing failure in the date column

dim(movie_data) # check dimension: 42204x7
```


# Data Preprocessing
```{r}
# Clean date 
  # Create a Year column
  movie_data[,"year"]<-year(as.Date(movie_data$release_date, "%Y",tryFormats = c("yyyy", "yyyy-mm-dd", "yyyy-mm")))

# Remove non-words components in the Summary column

  

# Eliminate missing values for the genres
  # check missing value for each column
  colSums(sapply(movie_data, is.na)) # genres has "[]" as the form of missing value
  
  # filter out empty cells in the genres column
  movie_data <- filter(movie_data, genres != "[]") 

# Remove duplicates
  # check duplicate rows
  sum(duplicated(movie_data)) # 0 

  # check duplicate summary--assumption: no films should share the same summary
  dedup.movie_data <- movie_data[!duplicated(movie_data$summary),] 
  
  
dim(dedup.movie_data) # check dimension: 42196 x 8

movie_data <- dedup.movie_data
```

# Genre Separation to Find Most Produced Genres
```{r}

# Clean the genre column
  # Eliminate the bracket in the genre column
    movie_data$genres <- gsub("\\[|\\]", "", movie_data$genres)
  
  # Lower case
    movie_data$genres <- tolower(movie_data$genres)
    
  # Eliminate space and convert two-word category into one-word
    movie_data$genres <- gsub(" ", "", movie_data$genres ) # e.g. "romance film" -> "romancefilm"
  
  # Elimiate the comma
    movie_data$genres <- gsub(",", " ", movie_data$genres)
    
# Create Corpus   
  genre <- Corpus(VectorSource(movie_data$genres))
  genre_dtm <- DocumentTermMatrix(genre)
  
  genre_freq <- colSums(as.matrix(genre_dtm))
  freq <- sort(colSums(as.matrix(genre_dtm)), decreasing=TRUE) 
  genre_wf <- data.frame(word=names(genre_freq), freq=genre_freq)
  
  
```

# Most Profitable Genres 
```{r}
# Remove rows with NAs in the box office revenue column
  revenue_movie<- movie_data %>%
    filter(box_office_revenue > 0)


```

# Characteristic of the Movie Summaries
```{r}
selected_genre = "action"

# Filter the summary based on the genre
  char_movie <- movie_data %>% 
    filter(str_detect(genres, selected_genre)) %>% 
    select(genres, summary)
  
# Tokenization
  char_movie <- char_movie %>%
    unnest_tokens(word, summary)
  
# Remove stop words
  char_movie <- char_movie %>%
    anti_join(stop_words) 
  
# Counts and word frequency
  char_movie %>%
    count(word, sort = TRUE) %>%
    filter(n>2000) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip()
  
```



```{r}
sessionInfo()
```

